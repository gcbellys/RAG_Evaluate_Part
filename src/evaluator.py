#!/usr/bin/env python3
"""
æ•´åˆçš„è¯„ä¼°å™¨
åŒ…å«æ‰€æœ‰è¯„ä¼°ã€ç»“æœä¿å­˜å’ŒæŠ¥å‘Šç”ŸæˆåŠŸèƒ½
"""

import json
from datetime import datetime
from typing import Dict, Any, List
from pathlib import Path

class Evaluator:
    """æ•´åˆçš„è¯„ä¼°å™¨ - æ”¯æŒå¤šç§è¯„ä¼°æ–¹æ³•å’Œç»“æœä¿å­˜"""
    
    def __init__(self):
        pass
    
    def evaluate_single_response(self, 
                               api_response: Dict[str, Any], 
                               expected_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è¯„ä¼°å•ä¸ªAPIå“åº”çš„è§£å‰–ä½ç½®å‡†ç¡®æ€§"""
        if not api_response.get('success', False):
            return {
                'overall_score': 0.0,
                'precision': 0.0,
                'recall': 0.0,
                'overgeneration_penalty': 0.0,
                'detailed_analysis': 'APIè°ƒç”¨å¤±è´¥'
            }
        
        # è·å–æœŸæœ›å’Œå®é™…çš„è§£å‰–ä½ç½®
        expected_locations = []
        for expected_result in expected_results:
            expected_locations.extend(expected_result.get('anatomicalLocations', []))
        
        # å»é‡
        expected_locations = list(set(expected_locations))
        
        actual_locations = []
        # æ£€æŸ¥å¤šç§å¯èƒ½çš„å­—æ®µå
        if 'parsed_data' in api_response and api_response['parsed_data']:
            actual_locations = api_response['parsed_data'].get('anatomical_locations', [])
        elif 'anatomical_locations' in api_response and api_response['anatomical_locations']:
            actual_locations = api_response['anatomical_locations']
        elif 'parsed_response' in api_response and api_response['parsed_response']:
            actual_locations = api_response['parsed_response'].get('anatomicalLocations', [])
        
        if not expected_locations or not actual_locations:
            return {
                'overall_score': 0.0,
                'precision': 0.0,
                'recall': 0.0,
                'overgeneration_penalty': 0.0,
                'detailed_analysis': 'ç¼ºå°‘è§£å‰–ä½ç½®ä¿¡æ¯'
            }
        
        # 1. è®¡ç®—Precision (ç²¾ç¡®ç‡) - 40%æƒé‡
        precision = self._calculate_precision(actual_locations, expected_locations)
        
        # 2. è®¡ç®—Recall (å¬å›ç‡) - 40%æƒé‡
        recall = self._calculate_recall(actual_locations, expected_locations)
        
        # 3. è®¡ç®—è¿‡åº¦ç”Ÿæˆæƒ©ç½š - 20%æƒé‡
        overgeneration_penalty = self._calculate_overgeneration_penalty(actual_locations, expected_locations)
        
        # 4. è®¡ç®—ç»¼åˆå¾—åˆ† (100åˆ†åˆ¶)
        overall_score = (precision * 0.4 + recall * 0.4 + overgeneration_penalty * 0.2) * 100
        
        # 5. ç”Ÿæˆè¯¦ç»†åˆ†æ
        analysis = self._generate_analysis(actual_locations, expected_locations, precision, recall, overgeneration_penalty)
        
        return {
            'overall_score': round(overall_score, 1),
            'precision': round(precision * 100, 1),
            'recall': round(recall * 100, 1),
            'overgeneration_penalty': round(overgeneration_penalty * 100, 1),
            'detailed_analysis': analysis
        }
    
    def evaluate_report_responses(self, report_results: Dict[str, Any]) -> Dict[str, Any]:
        """è¯„ä¼°æ•´ä¸ªReportçš„æ‰€æœ‰ç—‡çŠ¶å“åº”"""
        print(f"ğŸ“Š è¯„ä¼°Report {report_results['report_id']} çš„ {len(report_results['symptoms'])} ä¸ªç—‡çŠ¶...")
        
        report_evaluation = {
            'report_id': report_results['report_id'],
            'total_symptoms': report_results['total_symptoms'],
            'valid_symptoms': report_results['valid_symptoms'],
            'evaluation_timestamp': datetime.now().isoformat(),
            'symptom_evaluations': [],
            'summary': {
                'total_api_calls': 0,
                'successful_api_calls': 0,
                'failed_api_calls': 0,
                'average_overall_score': 0.0,
                'average_precision': 0.0,
                'average_recall': 0.0
            }
        }
        
        total_scores = []
        total_precision = []
        total_recall = []
        
        for symptom_result in report_results['symptoms']:
            symptom_evaluation = {
                'symptom_id': symptom_result['symptom_id'],
                'symptom_text': symptom_result['symptom_text'],
                'expected_results': symptom_result['expected_results'],
                'api_evaluations': {}
            }
            
            # è¯„ä¼°æ¯ä¸ªAPIçš„å“åº”
            for api_name, api_response in symptom_result['api_responses'].items():
                report_evaluation['summary']['total_api_calls'] += 1
                
                if api_response.get('success'):
                    report_evaluation['summary']['successful_api_calls'] += 1
                    
                    # è¯„ä¼°APIå“åº”
                    evaluation = self.evaluate_single_response(api_response, symptom_result['expected_results'])
                    symptom_evaluation['api_evaluations'][api_name] = evaluation
                    
                    # ç´¯è®¡åˆ†æ•°
                    total_scores.append(evaluation['overall_score'])
                    total_precision.append(evaluation['precision'])
                    total_recall.append(evaluation['recall'])
                else:
                    report_evaluation['summary']['failed_api_calls'] += 1
                    symptom_evaluation['api_evaluations'][api_name] = {
                        'overall_score': 0.0,
                        'precision': 0.0,
                        'recall': 0.0,
                        'overgeneration_penalty': 0.0,
                        'detailed_analysis': f"APIè°ƒç”¨å¤±è´¥: {api_response.get('error', 'æœªçŸ¥é”™è¯¯')}"
                    }
            
            report_evaluation['symptom_evaluations'].append(symptom_evaluation)
        
        # è®¡ç®—å¹³å‡åˆ†æ•°
        if total_scores:
            report_evaluation['summary']['average_overall_score'] = round(sum(total_scores) / len(total_scores), 1)
            report_evaluation['summary']['average_precision'] = round(sum(total_precision) / len(total_precision), 1)
            report_evaluation['summary']['average_recall'] = round(sum(total_recall) / len(total_recall), 1)
        
        return report_evaluation
    
    def save_report_results(self, report_results: Dict[str, Any], report_evaluation: Dict[str, Any], output_dir: Path):
        """æŒ‰Reportçº§åˆ«ä¿å­˜ç»“æœï¼Œæ–‡ä»¶åæ ¼å¼ä¸ºreport:i_baseline_evaluation_standardized"""
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # æ„é€ Reportç»“æœæ–‡ä»¶å
        report_id = report_results['report_id']
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = output_dir / f"report:{report_id}_baseline_evaluation_standardized.json"
        
        # å‡†å¤‡ä¿å­˜çš„æ•°æ®
        evaluation_results = {
            'metadata': {
                'report_id': report_id,
                'file_path': report_results['file_path'],
                'processing_timestamp': report_results['processing_timestamp'],
                'evaluation_timestamp': report_evaluation['evaluation_timestamp'],
                'total_symptoms': report_results['total_symptoms'],
                'valid_symptoms': report_results['valid_symptoms'],
                'api_clients': list(report_results['symptoms'][0]['api_responses'].keys()) if report_results['symptoms'] else []
            },
            'symptoms': []
        }
        
        # å¤„ç†æ¯ä¸ªç—‡çŠ¶çš„ç»“æœ
        for symptom_result in report_results['symptoms']:
            symptom_data = {
                'symptom_id': symptom_result['symptom_id'],
                'symptom_text': symptom_result['symptom_text'],
                'expected_results': symptom_result['expected_results'],
                'total_u_units': symptom_result['total_u_units'],
                'api_responses': {}
            }
            
            # æ ‡å‡†åŒ–APIå“åº”
            for client_name, response in symptom_result['api_responses'].items():
                parsed_response = {}
                if response.get('success'):
                    try:
                        # å»é™¤å¯èƒ½çš„Markdownä»£ç å—æ ‡è®°
                        text = response['response'].strip().replace('```json', '').replace('```', '').strip()
                        parsed_response = json.loads(text)
                    except (json.JSONDecodeError, AttributeError):
                        response['success'] = False
                        response['error'] = "Failed to parse JSON response"
                
                symptom_data['api_responses'][client_name] = {
                    'success': response.get('success', False),
                    'model': response.get('model', 'Unknown'),
                    'organ_name': parsed_response.get('organName', ''),
                    'anatomical_locations': parsed_response.get('anatomicalLocations', []),
                    'usage': response.get('usage', {}),
                    'error': response.get('error')
                }
            
            evaluation_results['symptoms'].append(symptom_data)
        
        # æ·»åŠ è¯„ä¼°æ‘˜è¦
        evaluation_results['evaluation_summary'] = report_evaluation['summary']
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        try:
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(evaluation_results, f, ensure_ascii=False, indent=2)
            print(f"âœ… Report {report_id} ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
            return str(results_file)
        except Exception as e:
            print(f"âŒ ä¿å­˜Report {report_id} ç»“æœå¤±è´¥: {e}")
            raise
    
    def _calculate_precision(self, actual_locations: List[str], expected_locations: List[str]) -> float:
        """è®¡ç®—Precision (ç²¾ç¡®ç‡)"""
        if not actual_locations:
            return 0.0
        
        # è®¡ç®—æ­£ç¡®è¿”å›çš„æ•°é‡
        correct_count = 0
        for location in actual_locations:
            if location in expected_locations:
                correct_count += 1
        
        # Precision = æ­£ç¡®æ•°é‡ / å®é™…è¿”å›æ€»æ•°
        precision = correct_count / len(actual_locations)
        return precision
    
    def _calculate_recall(self, actual_locations: List[str], expected_locations: List[str]) -> float:
        """è®¡ç®—Recall (å¬å›ç‡)"""
        if not expected_locations:
            return 0.0
        
        # è®¡ç®—æ­£ç¡®è¿”å›çš„æ•°é‡
        correct_count = 0
        for location in actual_locations:
            if location in expected_locations:
                correct_count += 1
        
        # Recall = æ­£ç¡®æ•°é‡ / æœŸæœ›æ€»æ•°
        recall = correct_count / len(expected_locations)
        return recall
    
    def _calculate_overgeneration_penalty(self, actual_locations: List[str], expected_locations: List[str]) -> float:
        """è®¡ç®—è¿‡åº¦ç”Ÿæˆæƒ©ç½š"""
        if not expected_locations:
            return 0.0
        
        # è®¡ç®—è¿”å›æ•°é‡ä¸æœŸæœ›æ•°é‡çš„æ¯”ä¾‹
        ratio = len(actual_locations) / len(expected_locations)
        
        # æƒ©ç½šæœºåˆ¶ï¼š
        # - å¦‚æœè¿”å›æ•°é‡ <= æœŸæœ›æ•°é‡ï¼šæ— æƒ©ç½š (1.0åˆ†)
        # - å¦‚æœè¿”å›æ•°é‡ > æœŸæœ›æ•°é‡ä¸” <= 2å€ï¼šçº¿æ€§æƒ©ç½š (1.0 â†’ 0.5)
        # - å¦‚æœè¿”å›æ•°é‡ > 2å€ä¸” <= 3å€ï¼šçº¿æ€§æƒ©ç½š (0.5 â†’ 0.0)
        # - å¦‚æœè¿”å›æ•°é‡ > 3å€ï¼šæœ€å¤§æƒ©ç½š (0.0åˆ†)
        
        if ratio <= 1.0:
            # æ— è¿‡åº¦ç”Ÿæˆï¼Œæ— æƒ©ç½š
            penalty = 1.0
        elif ratio <= 2.0:
            # çº¿æ€§æƒ©ç½šï¼šä»1.0é™åˆ°0.5
            penalty = 1.0 - (ratio - 1.0) * 0.5
        elif ratio <= 3.0:
            # çº¿æ€§æƒ©ç½šï¼šä»0.5é™åˆ°0.0
            penalty = 0.5 - (ratio - 2.0) * 0.5
        else:
            # è¶…è¿‡3å€ï¼Œæœ€å¤§æƒ©ç½š
            penalty = 0.0
        
        return penalty
    
    def _generate_analysis(self, actual_locations: List[str], expected_locations: List[str], 
                          precision: float, recall: float, overgeneration_penalty: float) -> str:
        """ç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Š"""
        # è®¡ç®—æ­£ç¡®æ•°é‡
        correct_count = 0
        for location in actual_locations:
            if location in expected_locations:
                correct_count += 1
        
        analysis = f"Precision(ç²¾ç¡®ç‡): {correct_count}/{len(actual_locations)} ({precision:.1%}); "
        analysis += f"Recall(å¬å›ç‡): {correct_count}/{len(expected_locations)} ({recall:.1%}); "
        analysis += f"è¿‡åº¦ç”Ÿæˆæƒ©ç½š: {overgeneration_penalty:.1%}"
        
        return analysis
