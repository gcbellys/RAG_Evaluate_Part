#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç‹¬ç«‹è„šæœ¬ï¼šä½¿ç”¨å·²æœ‰çš„RAGæ£€ç´¢ç»“æžœé‡æ–°è¿è¡ŒLLMè¯„ä¼°

åŠŸèƒ½:
1. æ ¹æ®æŠ¥å‘ŠIDï¼Œè‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„RAGæ£€ç´¢ç¼“å­˜æ–‡ä»¶ã€‚
2. é€ä¸€å¤„ç†ç¼“å­˜æ–‡ä»¶ä¸­çš„æ¯ä¸ªç—‡çŠ¶ã€‚
3. å°†RAGæ£€ç´¢ç»“æžœæ ¼å¼åŒ–åŽï¼Œæž„å»ºå¢žå¼ºåž‹Promptã€‚
4. è°ƒç”¨APIManagerï¼Œè®©æ‰€æœ‰é…ç½®çš„LLMé‡æ–°å¤„ç†è¿™äº›å¢žå¼ºåž‹Promptã€‚
5. å°†æ–°çš„LLMè¾“å‡ºç»“æžœä¿å­˜åˆ°ä¸“å±žçš„æ–‡ä»¶å¤¹ä¸­ã€‚
"""
import os
import sys
import json
import argparse
import logging
import shutil
from datetime import datetime
from typing import Dict, List, Any
from pathlib import Path
import glob

# --- å…³é”®ï¼šç¡®ä¿è„šæœ¬èƒ½æ‰¾åˆ°srcç›®å½•ä¸‹çš„æ¨¡å— ---
# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„ä¸­
sys.path.append(str(Path(__file__).resolve().parent / "src"))

try:
    from config_loader import ConfigLoader
    from api_manager import APIManager
    from evaluator import Evaluator
    from utils.logger import ReportLogger
except ImportError as e:
    print("é”™è¯¯: æ— æ³•å¯¼å…¥å¿…è¦çš„æ¨¡å—ã€‚è¯·ç¡®ä¿æ­¤è„šæœ¬ä½äºŽé¡¹ç›®æ ¹ç›®å½•ï¼Œå¹¶ä¸”'src'æ–‡ä»¶å¤¹å­˜åœ¨ã€‚")
    print(f"è¯¦ç»†é”™è¯¯: {e}")
    sys.exit(1)


class RerunWorkflow:
    """ä½¿ç”¨å·²æœ‰RAGç»“æžœé‡æ–°è¿è¡ŒLLMçš„å·¥ä½œæµ"""

    def __init__(self, report_id: int, config_path: str = "config/config.yaml"):
        self.report_id = report_id
        self.config = ConfigLoader(config_path)
        self.api_manager = APIManager()
        self.evaluator = Evaluator()
        self.logger = ReportLogger()

        # --- è·¯å¾„å®šä¹‰ ---
        # RAGç¼“å­˜æ–‡ä»¶çš„å­˜æ”¾ä½ç½®
        self.rag_output_dir = Path("/home/duojiechen/Projects/Rag_system/Rag_Evaluate/final_result/rag_search_output")
        
        # ç»Ÿä¸€åœ¨final_resultä¸‹ç®¡ç†æ‰€æœ‰ç»“æžœ
        self.final_result_dir = Path("final_result")
        self.baseline_results_dir = self.final_result_dir / "baseline_results"
        self.rerun_results_dir = self.final_result_dir / "rerun_with_rag"
        self.comparison_results_dir = self.final_result_dir / "rerun_comparisons"
        
        # åˆ›å»ºæ‰€æœ‰å¿…è¦çš„ç›®å½•
        for dir_path in [self.baseline_results_dir, self.rerun_results_dir, self.comparison_results_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
        
        print(f"ðŸŽ¯ æŠ¥å‘ŠID: {self.report_id}")
        print(f"ðŸ” RAGç¼“å­˜ç›®å½•: {self.rag_output_dir}")
        print(f"ðŸ“‹ Baselineç»“æžœç›®å½•: {self.baseline_results_dir}")
        print(f"ðŸ’¾ RAGå¢žå¼ºç»“æžœç›®å½•: {self.rerun_results_dir}")
        print(f"ðŸ“Š å¯¹æ¯”ç»“æžœç›®å½•: {self.comparison_results_dir}")

    def find_latest_rag_cache(self) -> Path:
        """æ ¹æ®æŠ¥å‘ŠIDæŸ¥æ‰¾æœ€æ–°çš„RAGç»“æžœæ–‡ä»¶ (.jsonl)"""
        search_pattern = f"report_{self.report_id}_ragoutcome:*.jsonl"
        files = glob.glob(str(self.rag_output_dir / search_pattern))
        
        if not files:
            raise FileNotFoundError(f"åœ¨ç›®å½• {self.rag_output_dir} ä¸­æœªæ‰¾åˆ°æŠ¥å‘ŠID {self.report_id} çš„RAGç¼“å­˜æ–‡ä»¶ã€‚")
        
        latest_file = max(files, key=os.path.getctime)
        print(f"ðŸ” æ‰¾åˆ°æœ€æ–°çš„RAGç¼“å­˜æ–‡ä»¶: {Path(latest_file).name}")
        return Path(latest_file)

    def find_or_create_baseline_results(self) -> Path:
        """æŸ¥æ‰¾æˆ–åˆ›å»ºå¯¹åº”çš„baselineç»“æžœæ–‡ä»¶"""
        # å…ˆåœ¨ç»Ÿä¸€çš„baseline_resultsç›®å½•ä¸­æŸ¥æ‰¾
        search_pattern = f"report_diagnostic_{self.report_id}_evaluation_*.json"
        files = glob.glob(str(self.baseline_results_dir / search_pattern))
        
        # è¿‡æ»¤æŽ‰æ ‡å‡†åŒ–ç‰ˆæœ¬å’Œç”¨æˆ·æ ¼å¼ç‰ˆæœ¬
        detailed_files = [f for f in files if 'standardized' not in f and 'user_format' not in f]
        
        if detailed_files:
            latest_file = max(detailed_files, key=os.path.getctime)
            print(f"ðŸ“‹ æ‰¾åˆ°å·²æœ‰baselineç»“æžœ: {Path(latest_file).name}")
            return Path(latest_file)
        
        # å¦‚æžœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•åœ¨æ—§çš„resultsç›®å½•æŸ¥æ‰¾
        old_results_dir = Path("results")
        old_files = glob.glob(str(old_results_dir / search_pattern))
        old_detailed_files = [f for f in old_files if 'standardized' not in f and 'user_format' not in f]
        
        if old_detailed_files:
            latest_file = max(old_detailed_files, key=os.path.getctime)
            print(f"ðŸ“‹ æ‰¾åˆ°æ—§çš„baselineç»“æžœ: {Path(latest_file).name}")
            return Path(latest_file)
        
        # å¦‚æžœéƒ½æ²¡æœ‰æ‰¾åˆ°ï¼Œè‡ªåŠ¨è¿è¡Œbaselineè¯„ä¼°
        print(f"ðŸš¨ æœªæ‰¾åˆ°æŠ¥å‘ŠID {self.report_id} çš„baselineç»“æžœï¼Œæ­£åœ¨è‡ªåŠ¨ç”Ÿæˆ...")
        return self._run_baseline_evaluation()

    def _run_baseline_evaluation(self) -> Path:
        """è¿è¡Œbaselineè¯„ä¼°å¹¶è¿”å›žç»“æžœæ–‡ä»¶è·¯å¾„"""
        print(f"\nðŸ”„ æ­£åœ¨ä¸ºæŠ¥å‘Š {self.report_id} è¿è¡Œbaselineè¯„ä¼°...")
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        from data_loader import DataLoader
        data_loader = DataLoader()
        
        # å¯»æ‰¾æµ‹è¯•æ–‡ä»¶
        test_data_path = Path("/home/duojiechen/Projects/Central_Data/RAG_System/test_set")
        test_file = test_data_path / f"diagnostic_{self.report_id}.json"
        
        if not test_file.exists():
            raise FileNotFoundError(f"æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
        
        # åŠ è½½æŠ¥å‘Šæ•°æ®
        report_data = data_loader.load_report_data(test_file)
        if 'error' in report_data:
            raise ValueError(f"åŠ è½½æŠ¥å‘Šæ•°æ®å¤±è´¥: {report_data['error']}")
        
        print(f"ðŸ“„ å·²åŠ è½½æŠ¥å‘Šæ•°æ®ï¼ŒåŒ…å« {len(report_data.get('symptoms', []))} ä¸ªç—‡çŠ¶")
        
        # å¤„ç†æŠ¥å‘Š - ä½¿ç”¨ä¸Žmain_workflow.pyç›¸åŒçš„é€»è¾‘
        report_results = self._process_baseline_report(report_data)
        
        # ä¿å­˜ç»“æžœåˆ°ç»Ÿä¸€ç›®å½•
        result_file = self._save_baseline_results(report_results)
        
        print(f"âœ… Baselineè¯„ä¼°å®Œæˆï¼Œç»“æžœä¿å­˜è‡³: {result_file}")
        return result_file

    def _process_baseline_report(self, report_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†baselineæŠ¥å‘Šï¼Œä¸Žmain_workflow.pyé€»è¾‘ä¸€è‡´"""
        report_id = report_data.get('report_id', 'unknown')
        symptoms = report_data.get('symptoms', [])
        
        print(f"ðŸ”„ æ­£åœ¨å¤„ç†baselineæŠ¥å‘Š {report_id}ï¼ŒåŒ…å« {len(symptoms)} ä¸ªç—‡çŠ¶")
        
        report_results = {
            'report_id': report_id,
            'timestamp': datetime.now().isoformat(),
            'symptoms': []
        }
        
        # åŠ è½½ç³»ç»Ÿæç¤ºè¯
        system_prompt_path = Path("prompt/system_prompt.txt")
        if system_prompt_path.exists():
            with open(system_prompt_path, 'r', encoding='utf-8') as f:
                system_prompt = f.read().strip()
        else:
            system_prompt = "ä½ æ˜¯ä¸€ä¸ªåŒ»å­¦ä¸“å®¶ï¼Œè¯·æ ¹æ®ç—‡çŠ¶è¯†åˆ«ç›¸å…³çš„å™¨å®˜å’Œè§£å‰–ä½ç½®ã€‚"
        
        # å¤„ç†æ¯ä¸ªç—‡çŠ¶
        for i, symptom_item in enumerate(symptoms, 1):
            symptom_id = symptom_item.get('symptom_id', 'unknown')
            symptom_text = symptom_item.get('symptom_text', '')
            
            print(f"  ðŸ”„ å¤„ç†ç—‡çŠ¶ {i}/{len(symptoms)}: {symptom_text[:50]}...")
            
            # æå–æœŸæœ›çš„å™¨å®˜ä¿¡æ¯
            expected_organs = symptom_item.get('expected_results', [])
            
            try:
                # è°ƒç”¨APIå¤„ç†ç—‡çŠ¶ï¼ˆbaselineï¼Œä¸ä½¿ç”¨RAGï¼‰
                api_result = self.api_manager.process_symptom(symptom_item, system_prompt)
                
                # æž„å»ºç—‡çŠ¶æ•°æ®ç»“æž„
                symptom_data = {
                    'symptom_id': symptom_id,
                    'diagnosis': symptom_text,
                    'expected_organs': expected_organs,
                    'api_responses': {}
                }
                
                # å¤„ç†æ¯ä¸ªAPIçš„å“åº”å’Œè¯„ä¼°
                for api_name, response in api_result.items():
                    api_response_data = {
                        'response': response.get('response', ''),
                        'parsed_data': response.get('parsed_data', {}),
                        'organ_name': response.get('organ_name', ''),
                        'anatomical_locations': response.get('anatomical_locations', [])
                    }
                    
                    # è¯„ä¼°è¿™ä¸ªAPIçš„å“åº”
                    if response.get('success') and response.get('parsed_data'):
                        evaluation = self.evaluator.evaluate_single_response(
                            api_response=response,
                            expected_results=expected_organs
                        )
                        api_response_data['evaluation'] = evaluation
                    else:
                        api_response_data['evaluation'] = {
                            'overall_score': 0.0,
                            'precision': 0.0,
                            'recall': 0.0,
                            'overgeneration_penalty': 0.0,
                            'detailed_analysis': 'APIè°ƒç”¨å¤±è´¥æˆ–æ— æœ‰æ•ˆæ•°æ®'
                        }
                    
                    symptom_data['api_responses'][api_name] = api_response_data
                
                report_results['symptoms'].append(symptom_data)
                
            except Exception as e:
                error_msg = f"å¤„ç†ç—‡çŠ¶ {symptom_id} æ—¶å‡ºé”™: {str(e)}"
                print(f"    âŒ {error_msg}")
                
                # å³ä½¿å‡ºé”™ä¹Ÿè¦ä¿å­˜ç—‡çŠ¶çš„åŸºæœ¬ä¿¡æ¯
                symptom_data = {
                    'symptom_id': symptom_id,
                    'diagnosis': symptom_text,
                    'expected_organs': expected_organs,
                    'error': str(e),
                    'api_responses': {}
                }
                report_results['symptoms'].append(symptom_data)
        
        return report_results

    def _save_baseline_results(self, report_results: Dict[str, Any]) -> Path:
        """ä¿å­˜baselineç»“æžœåˆ°ç»Ÿä¸€ç›®å½•"""
        report_id = report_results['report_id']
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜è¯¦ç»†ç»“æžœ
        detailed_filename = f"report_diagnostic_{report_id}_evaluation_{timestamp}.json"
        detailed_path = self.baseline_results_dir / detailed_filename
        
        with open(detailed_path, 'w', encoding='utf-8') as f:
            json.dump(report_results, f, ensure_ascii=False, indent=2)
        
        print(f"ðŸ’¾ Baselineç»“æžœå·²ä¿å­˜: {detailed_path}")
        return detailed_path

    def _build_augmented_prompt(self, original_query: str, rag_results: Dict[str, Any]) -> str:
        """
        æ ¹æ®RAGç»“æžœæž„å»ºå¢žå¼ºåž‹Promptã€‚
        æ­¤é€»è¾‘ä¸Žcomparision_workflow.pyä¿æŒä¸€è‡´ã€‚
        """
        primary_refs = []
        if not rag_results:
            return original_query

        # éåŽ†rag_s_1_id, rag_s_2_idç­‰
        for key, value in rag_results.items():
            if isinstance(value, dict) and 'units' in value:
                for unit in value.get('units', []):
                    u_unit = unit.get('u_unit', {})
                    text = u_unit.get('d_diagnosis', '')
                    organ = u_unit.get('o_organ', {})
                    primary_refs.append({'text': text, 'organ': organ})

        if not primary_refs:
            return original_query

        def fmt_ref(ref: Dict[str, Any]) -> str:
            organ_part = ""
            organ = ref.get('organ')
            if organ and isinstance(organ, dict):
                name = organ.get('organName', '')
                locs = organ.get('anatomicalLocations', [])
                loc_str = ", ".join(locs)
                organ_part = f" | organ: {name} | locations: {loc_str}"
            text = ref.get('text', '')
            return f"- {text}{organ_part}".strip()

        primary_block = "\n".join([fmt_ref(r) for r in primary_refs])
        
        # --- Promptæ¨¡æ¿ ---
        aug_parts = [
            "ä»¥ä¸‹æ˜¯æˆ‘çš„ç—‡çŠ¶æè¿°ï¼š",
            original_query.strip(),
            "",
            "ä¸‹é¢ç»™ä½ ä¸€äº›æ¥è‡ªæ£€ç´¢ç³»ç»Ÿï¼ˆRAGï¼‰çš„ç›¸å…³å‚è€ƒï¼Œè¯·åœ¨å›žç­”æ—¶ä»¥è¿™äº›å‚è€ƒä¸ºä¸»è¦ä¾æ®è¿›è¡ŒæŽ¨ç†ä¸Žå½’çº³ï¼ŒåŒæ—¶ä¸¥æ ¼è¾“å‡ºJSONç»“æž„ï¼š",
            "--- å‚è€ƒèµ„æ–™ ---",
            primary_block if primary_block else "(æ— )",
            "--- è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯å›žç­” ---",
        ]
        return "\n".join(aug_parts)

    def run(self):
        """æ‰§è¡Œå®Œæ•´çš„å·¥ä½œæµç¨‹"""
        try:
            # 1. åˆå§‹åŒ–APIç®¡ç†å™¨
            print("\nðŸ”§ åˆå§‹åŒ–APIè¿žæŽ¥...")
            if not self.api_manager.initialize_clients(self.config.config):
                print("âŒ APIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
                return
            
            # 2. æŸ¥æ‰¾RAGç¼“å­˜æ–‡ä»¶
            rag_cache_file = self.find_latest_rag_cache()
            
            # 3. æŸ¥æ‰¾æˆ–åˆ›å»ºbaselineç»“æžœ
            baseline_file = self.find_or_create_baseline_results()
            baseline_data = {}
            if baseline_file:
                with open(baseline_file, 'r', encoding='utf-8') as f:
                    baseline_results = json.load(f)
                    # å°†baselineç»“æžœæŒ‰ç—‡çŠ¶æ–‡æœ¬ç´¢å¼•ï¼ŒåŒæ—¶ä¿å­˜æœŸæœ›ç»“æžœ
                    for symptom in baseline_results.get('symptoms', []):
                        diagnosis = symptom.get('diagnosis', '')
                        baseline_data[diagnosis] = {
                            'api_responses': symptom.get('api_responses', {}),
                            'expected_organs': symptom.get('expected_organs', [])
                        }
            
            # 4. å¤„ç†RAGç¼“å­˜æ–‡ä»¶
            all_rag_results = {}
            all_comparisons = {}
            
            print(f"\nðŸš€ å¼€å§‹å¤„ç†RAGç¼“å­˜æ–‡ä»¶...")
            
            # åŠ è½½ç³»ç»Ÿæç¤ºè¯
            system_prompt_path = Path("prompt/system_prompt.txt")
            system_prompt = system_prompt_path.read_text(encoding='utf-8') if system_prompt_path.exists() else "ä½ æ˜¯ä¸€ä¸ªåŒ»å­¦ä¸“å®¶ï¼Œè¯·æ ¹æ®ç—‡çŠ¶è¯†åˆ«ç›¸å…³çš„å™¨å®˜å’Œè§£å‰–ä½ç½®ã€‚"
            
            with open(rag_cache_file, 'r', encoding='utf-8') as f:
                for i, line in enumerate(f):
                    try:
                        data = json.loads(line)
                        original_query = data.get("query", "").strip()
                        rag_s_block = data.get("s", {})
                        
                        if not original_query:
                            print(f"âš ï¸  ç¬¬ {i+1} è¡Œç¼ºå°‘ 'query' å­—æ®µï¼Œè·³è¿‡ã€‚")
                            continue
                            
                        print(f"\n--- æ­£åœ¨å¤„ç†ç—‡çŠ¶ {i+1}: {original_query[:50]}... ---")
                        
                        # æž„å»ºå¢žå¼ºåž‹Prompt
                        augmented_prompt = self._build_augmented_prompt(original_query, rag_s_block)
                        
                        # è°ƒç”¨æ‰€æœ‰APIè¿›è¡Œå¤„ç†
                        symptom_item_for_api = {
                            'symptom_id': f'rerun_{self.report_id}_{i}',
                            'symptom_text': augmented_prompt,
                            'expected_results': []  # å¯ä»¥ä»ŽåŽŸå§‹æ•°æ®ä¸­æå–
                        }
                        
                        api_results = self.api_manager.process_symptom(symptom_item_for_api, system_prompt)
                        
                        # ä¸ºæ¯ä¸ªAPIç»“æžœæ·»åŠ è¯„ä¼°ï¼ˆå¦‚æžœæœ‰æœŸæœ›ç»“æžœï¼‰
                        for api_name, response in api_results.items():
                            if response.get('success') and response.get('parsed_data'):
                                # è¿™é‡Œå¯ä»¥æ·»åŠ è¯„ä¼°é€»è¾‘ï¼Œä½†ç›®å‰æˆ‘ä»¬åªå…³æ³¨APIå“åº”
                                pass
                        
                        all_rag_results[original_query] = {
                            'api_responses': api_results,
                            'rag_context': rag_s_block,
                            'augmented_prompt': augmented_prompt
                        }
                        
                        # å¦‚æžœæœ‰baselineæ•°æ®ï¼Œè¿›è¡Œå¯¹æ¯”
                        if original_query in baseline_data:
                            baseline_info = baseline_data[original_query]
                            baseline_api_responses = baseline_info['api_responses']
                            expected_results = baseline_info['expected_organs']  # ä½¿ç”¨baselineä¸­çš„æœŸæœ›ç»“æžœ
                            comparison = self._compare_responses(baseline_api_responses, api_results, expected_results)
                            all_comparisons[original_query] = comparison
                        
                        print(f"âœ… å®Œæˆç—‡çŠ¶å¤„ç†: {original_query[:30]}...")
                        
                    except json.JSONDecodeError:
                        print(f"âš ï¸  ç¬¬ {i+1} è¡Œä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œè·³è¿‡ã€‚")
                    except Exception as e:
                        print(f"âŒ å¤„ç†ç¬¬ {i+1} è¡Œæ—¶å‡ºé”™: {e}")
                        
            # 5. ä¿å­˜æœ€ç»ˆç»“æžœ
            if all_rag_results:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                
                # ä¿å­˜RAGå¢žå¼ºç»“æžœ
                rag_output_filename = self.rerun_results_dir / f"report_{self.report_id}_withRAG_{timestamp}.json"
                with open(rag_output_filename, 'w', encoding='utf-8') as f:
                    json.dump(all_rag_results, f, ensure_ascii=False, indent=2)
                
                print(f"\nâœ… RAGå¢žå¼ºç»“æžœå·²ä¿å­˜: {rag_output_filename}")
                
                # ä¿å­˜å¯¹æ¯”ç»“æžœï¼ˆå¦‚æžœæœ‰ï¼‰
                if all_comparisons:
                    comparison_filename = self.comparison_results_dir / f"report_{self.report_id}_comparison_{timestamp}.json"
                    with open(comparison_filename, 'w', encoding='utf-8') as f:
                        json.dump(all_comparisons, f, ensure_ascii=False, indent=2)
                    
                    print(f"âœ… å¯¹æ¯”ç»“æžœå·²ä¿å­˜: {comparison_filename}")
                    
                    # ç”Ÿæˆç®€åŒ–çš„è¯„æµ‹ç»“æžœæ–‡ä»¶
                    simplified_filename = self.comparison_results_dir / f"report_{self.report_id}_evaluation_summary_{timestamp}.json"
                    simplified_results = self._generate_evaluation_summary(all_comparisons, baseline_data)
                    with open(simplified_filename, 'w', encoding='utf-8') as f:
                        json.dump(simplified_results, f, ensure_ascii=False, indent=2)
                    
                    print(f"âœ… è¯„æµ‹æ‘˜è¦å·²ä¿å­˜: {simplified_filename}")
                    
                    # åˆ›å»ºä¸“é—¨çš„ç»“æžœæ–‡ä»¶å¤¹å¹¶ç”Ÿæˆåˆ†æ•°æŠ¥å‘Š
                    result_folder = self.comparison_results_dir / f"report_{self.report_id}_results_{timestamp}"
                    result_folder.mkdir(exist_ok=True)
                    
                    # ç§»åŠ¨evaluation_summaryåˆ°æ–°æ–‡ä»¶å¤¹
                    new_summary_path = result_folder / f"report_{self.report_id}_evaluation_summary.json"
                    shutil.move(str(simplified_filename), str(new_summary_path))
                    
                    # ç”Ÿæˆåˆ†æ•°æŠ¥å‘Š
                    score_report_path = self._generate_score_report(simplified_results, result_folder, timestamp)
                    
                    print(f"âœ… åˆ†æ•°æŠ¥å‘Šå·²ä¿å­˜: {score_report_path}")
                    print(f"ðŸ“ å®Œæ•´ç»“æžœå·²ä¿å­˜åˆ°: {result_folder}")
                
                print("\nðŸŽ‰ ===== ä»»åŠ¡å®Œæˆ! =====")
                print(f"ðŸ“Š æˆåŠŸå¤„ç†äº† {len(all_rag_results)} ä¸ªç—‡çŠ¶")
                print(f"\nðŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
                print(f"  ðŸ“‹ Baselineç»“æžœ: {baseline_file}")
                print(f"  ðŸ’¾ RAGå¢žå¼ºç»“æžœ: {rag_output_filename}")
                if all_comparisons:
                    print(f"  ðŸ“ˆ è¯¦ç»†å¯¹æ¯”ç»“æžœ: {comparison_filename}")
                    print(f"  ðŸ“‚ å®Œæ•´ç»“æžœæ–‡ä»¶å¤¹: {result_folder}")
                    print(f"    â”œâ”€â”€ ðŸ“ è¯„æµ‹æ‘˜è¦ (JSON): report_{self.report_id}_evaluation_summary.json")
                    print(f"    â””â”€â”€ ðŸ“Š åˆ†æ•°æŠ¥å‘Š (TXT): report_{self.report_id}_rag_score_report.txt")
                    print(f"\nâœ¨ åˆ†æ•°æŠ¥å‘ŠåŒ…å«:")
                    print(f"     - æ€»ä½“æ•ˆæžœæ¦‚è§ˆ (æ”¹å–„/è´Ÿé¢/æ— å˜åŒ–æ¯”ä¾‹)")
                    print(f"     - å¹³å‡æŒ‡æ ‡æ”¹å–„ (ç²¾ç¡®çŽ‡ã€å¬å›žçŽ‡ã€F1åˆ†æ•°ã€ç»¼åˆå¾—åˆ†)")
                    print(f"     - å„ç—‡çŠ¶è¯¦ç»†åˆ†æž")
                    print(f"     - ç»“è®ºä¸Žå»ºè®® (æœ€ä½³/æœ€å·®APIï¼Œæ€»ä½“RAGæ•ˆæžœè¯„ä¼°)")

        except FileNotFoundError as e:
            print(f"\nâŒ é”™è¯¯: {e}")
            print("   è¯·ç¡®ä¿æ‚¨å·²ä¸ºè¯¥æŠ¥å‘ŠIDæˆåŠŸè¿è¡Œäº†RAGæ£€ç´¢æ­¥éª¤ã€‚")
        except Exception as e:
            print(f"\nâŒ å·¥ä½œæµç¨‹æ‰§è¡Œæ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
            logging.error(f"å·¥ä½œæµç¨‹å¤±è´¥: {e}", exc_info=True)

    def _compare_responses(self, baseline_responses: Dict[str, Any], rag_responses: Dict[str, Any], expected_results: List[Dict[str, Any]] = None) -> Dict[str, Any]:
        """å¯¹æ¯”baselineå’ŒRAGå¢žå¼ºçš„APIå“åº”ï¼ŒåŒ…å«è¯¦ç»†çš„è¯„ä¼°æŒ‡æ ‡"""
        comparison = {}
        
        # æ‰¾åˆ°å…±åŒçš„API
        common_apis = set(baseline_responses.keys()) & set(rag_responses.keys())
        
        # å‡†å¤‡æœŸæœ›çš„è§£å‰–ä½ç½®ç”¨äºŽè¯„ä¼°
        expected_locations = []
        expected_organs = []
        if expected_results:
            for expected_result in expected_results:
                expected_locations.extend(expected_result.get('anatomicalLocations', []))
                organ_name = expected_result.get('organName', '')
                if organ_name:
                    expected_organs.append(organ_name)
        expected_locations = list(set(expected_locations))  # åŽ»é‡
        expected_organs = list(set(expected_organs))  # åŽ»é‡
        
        for api_name in common_apis:
            baseline_resp = baseline_responses.get(api_name, {})
            rag_resp = rag_responses.get(api_name, {})
            
            # æå–åŸºæœ¬ä¿¡æ¯
            baseline_organ = baseline_resp.get('organ_name', '')
            rag_organ = rag_resp.get('organ_name', '')
            baseline_locations = baseline_resp.get('anatomical_locations', [])
            rag_locations = rag_resp.get('anatomical_locations', [])
            
            # è®¡ç®—å™¨å®˜å‡†ç¡®çŽ‡
            baseline_organ_accuracy = self._calculate_organ_accuracy(baseline_organ, expected_organs)
            rag_organ_accuracy = self._calculate_organ_accuracy(rag_organ, expected_organs)
            
            # è®¡ç®—è§£å‰–ä½ç½®è¯„ä¼°æŒ‡æ ‡
            baseline_metrics = self._calculate_location_metrics(baseline_locations, expected_locations)
            rag_metrics = self._calculate_location_metrics(rag_locations, expected_locations)
            
            # è®¡ç®—æ”¹å–„æƒ…å†µ
            metrics_improvement = {
                'precision_improvement': rag_metrics['precision'] - baseline_metrics['precision'],
                'recall_improvement': rag_metrics['recall'] - baseline_metrics['recall'],
                'f1_improvement': rag_metrics['f1_score'] - baseline_metrics['f1_score'],
                'overall_improvement': rag_metrics['overall_score'] - baseline_metrics['overall_score']
            }
            
            comparison[api_name] = {
                # åŸºæœ¬å¯¹æ¯”ä¿¡æ¯
                'baseline_organ': baseline_organ,
                'rag_organ': rag_organ,
                'baseline_locations': baseline_locations,
                'rag_locations': rag_locations,
                'organ_changed': baseline_organ != rag_organ,
                'locations_changed': baseline_locations != rag_locations,
                
                # å™¨å®˜å‡†ç¡®çŽ‡è¯„ä¼°
                'baseline_organ_accuracy': baseline_organ_accuracy,
                'rag_organ_accuracy': rag_organ_accuracy,
                'organ_accuracy_improved': rag_organ_accuracy['category'] == 'exact_match' and baseline_organ_accuracy['category'] != 'exact_match',
                
                # è§£å‰–ä½ç½®è¯„ä¼°æŒ‡æ ‡
                'baseline_metrics': baseline_metrics,
                'rag_metrics': rag_metrics,
                'metrics_improvement': metrics_improvement,
                
                # ç»¼åˆè¯„ä¼°
                'overall_assessment': self._assess_overall_improvement(baseline_metrics, rag_metrics, baseline_organ_accuracy, rag_organ_accuracy)
            }
        
        return comparison

    def _calculate_organ_accuracy(self, predicted_organ: str, expected_organs: List[str]) -> Dict[str, Any]:
        """è®¡ç®—å™¨å®˜å‡†ç¡®çŽ‡"""
        if not expected_organs:
            return {
                'category': 'unknown',
                'score': 0.0,
                'description': 'æ— æœŸæœ›å™¨å®˜ä¿¡æ¯'
            }
        
        if not predicted_organ:
            return {
                'category': 'incorrect',
                'score': 0.0,
                'description': 'æœªè¯†åˆ«å‡ºä»»ä½•å™¨å®˜'
            }
        
        # ç²¾ç¡®åŒ¹é…
        if predicted_organ in expected_organs:
            return {
                'category': 'exact_match',
                'score': 1.0,
                'description': f'ç²¾ç¡®åŒ¹é…æœŸæœ›å™¨å®˜: {predicted_organ}'
            }
        
        # éƒ¨åˆ†åŒ¹é…æ£€æŸ¥ï¼ˆç®€å•çš„åŒ…å«å…³ç³»ï¼‰
        for expected_organ in expected_organs:
            if (predicted_organ.lower() in expected_organ.lower() or 
                expected_organ.lower() in predicted_organ.lower()):
                return {
                    'category': 'partial_match',
                    'score': 0.6,
                    'description': f'éƒ¨åˆ†åŒ¹é…: é¢„æµ‹"{predicted_organ}" vs æœŸæœ›"{expected_organ}"'
                }
        
        # å®Œå…¨é”™è¯¯
        return {
            'category': 'incorrect',
            'score': 0.0,
            'description': f'å®Œå…¨é”™è¯¯: é¢„æµ‹"{predicted_organ}" ä¸åŒ¹é…æœŸæœ›{expected_organs}'
        }

    def _calculate_location_metrics(self, predicted_locations: List[str], expected_locations: List[str]) -> Dict[str, float]:
        """è®¡ç®—è§£å‰–ä½ç½®çš„å„é¡¹è¯„ä¼°æŒ‡æ ‡"""
        if not expected_locations:
            return {
                'precision': 0.0,
                'recall': 0.0,
                'f1_score': 0.0,
                'overgeneration_penalty': 0.0,
                'overall_score': 0.0
            }
        
        if not predicted_locations:
            return {
                'precision': 0.0,
                'recall': 0.0,
                'f1_score': 0.0,
                'overgeneration_penalty': 0.0,
                'overall_score': 0.0
            }
        
        # è®¡ç®—æ­£ç¡®è¯†åˆ«çš„æ•°é‡
        correct_count = 0
        for location in predicted_locations:
            if location in expected_locations:
                correct_count += 1
        
        # ç²¾ç¡®çŽ‡ = æ­£ç¡®è¯†åˆ«æ•°é‡ / é¢„æµ‹æ€»æ•°é‡
        precision = correct_count / len(predicted_locations)
        
        # å¬å›žçŽ‡ = æ­£ç¡®è¯†åˆ«æ•°é‡ / æœŸæœ›æ€»æ•°é‡
        recall = correct_count / len(expected_locations)
        
        # F1åˆ†æ•°
        f1_score = 0.0
        if precision + recall > 0:
            f1_score = 2 * (precision * recall) / (precision + recall)
        
        # è¿‡åº¦ç”Ÿæˆæƒ©ç½š
        over_generation = max(0, len(predicted_locations) - len(expected_locations))
        overgeneration_penalty = 1.0 - (over_generation / max(len(expected_locations), 1))
        overgeneration_penalty = max(0.0, overgeneration_penalty)
        
        # ç»¼åˆå¾—åˆ† (100åˆ†åˆ¶)
        overall_score = (precision * 0.4 + recall * 0.4 + overgeneration_penalty * 0.2) * 100
        
        return {
            'precision': round(precision * 100, 1),
            'recall': round(recall * 100, 1),
            'f1_score': round(f1_score * 100, 1),
            'overgeneration_penalty': round(overgeneration_penalty * 100, 1),
            'overall_score': round(overall_score, 1)
        }

    def _assess_overall_improvement(self, baseline_metrics: Dict[str, float], rag_metrics: Dict[str, float], 
                                  baseline_organ: Dict[str, Any], rag_organ: Dict[str, Any]) -> str:
        """è¯„ä¼°RAGå¢žå¼ºçš„æ•´ä½“æ”¹å–„æƒ…å†µ"""
        improvements = []
        
        # å™¨å®˜å‡†ç¡®çŽ‡æ”¹å–„
        if rag_organ['score'] > baseline_organ['score']:
            improvements.append(f"å™¨å®˜è¯†åˆ«æ”¹å–„ ({baseline_organ['category']} â†’ {rag_organ['category']})")
        
        # å„é¡¹æŒ‡æ ‡æ”¹å–„
        if rag_metrics['precision'] > baseline_metrics['precision']:
            improvements.append(f"ç²¾ç¡®çŽ‡æå‡ {rag_metrics['precision'] - baseline_metrics['precision']:.1f}%")
        
        if rag_metrics['recall'] > baseline_metrics['recall']:
            improvements.append(f"å¬å›žçŽ‡æå‡ {rag_metrics['recall'] - baseline_metrics['recall']:.1f}%")
        
        if rag_metrics['f1_score'] > baseline_metrics['f1_score']:
            improvements.append(f"F1åˆ†æ•°æå‡ {rag_metrics['f1_score'] - baseline_metrics['f1_score']:.1f}%")
        
        if rag_metrics['overall_score'] > baseline_metrics['overall_score']:
            improvements.append(f"ç»¼åˆå¾—åˆ†æå‡ {rag_metrics['overall_score'] - baseline_metrics['overall_score']:.1f}åˆ†")
        
        if improvements:
            return "âœ… RAGå¢žå¼ºæœ‰æ•ˆ: " + "; ".join(improvements)
        elif rag_metrics['overall_score'] == baseline_metrics['overall_score']:
            return "âšª RAGå¢žå¼ºæ— æ˜Žæ˜¾å½±å“"
        else:
            return "âŒ RAGå¢žå¼ºå¯èƒ½äº§ç”Ÿè´Ÿé¢å½±å“"

    def _generate_evaluation_summary(self, all_comparisons: Dict[str, Any], baseline_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆç®€åŒ–çš„è¯„æµ‹ç»“æžœæ‘˜è¦ï¼ŒæŒ‰ç”¨æˆ·è¦æ±‚çš„æ ¼å¼"""
        evaluation_summary = {}
        
        for symptom_text, comparisons in all_comparisons.items():
            # èŽ·å–æœŸæœ›ç»“æžœ
            expected_organs = []
            expected_locations = []
            if symptom_text in baseline_data:
                for expected_result in baseline_data[symptom_text]['expected_organs']:
                    if isinstance(expected_result, dict):
                        organ_name = expected_result.get('organName', '')
                        locations = expected_result.get('anatomicalLocations', [])
                        if organ_name:
                            expected_organs.append(organ_name)
                        expected_locations.extend(locations)
            
            # åŽ»é‡
            expected_organs = list(set(expected_organs))
            expected_locations = list(set(expected_locations))
            
            symptom_summary = {
                "expected_outcome": {
                    "organs": expected_organs,
                    "anatomical_locations": expected_locations
                }
            }
            
            # ä¸ºæ¯ä¸ªAPIç”Ÿæˆå¯¹æ¯”ç»“æžœ
            for api_name, comparison in comparisons.items():
                # Baseline APIç»“æžœ
                baseline_outcome = {
                    "organ": comparison.get('baseline_organ', ''),
                    "anatomical_locations": comparison.get('baseline_locations', []),
                    "metrics": comparison.get('baseline_metrics', {}),
                    "organ_accuracy": comparison.get('baseline_organ_accuracy', {})
                }
                
                # RAGå¢žå¼ºç»“æžœ
                rag_outcome = {
                    "organ": comparison.get('rag_organ', ''),
                    "anatomical_locations": comparison.get('rag_locations', []),
                    "metrics": comparison.get('rag_metrics', {}),
                    "organ_accuracy": comparison.get('rag_organ_accuracy', {})
                }
                
                # æ”¹å–„åˆ†æž
                improvement_analysis = {
                    "metrics_improvement": comparison.get('metrics_improvement', {}),
                    "assessment": comparison.get('overall_assessment', ''),
                    "organ_improved": comparison.get('organ_accuracy_improved', False),
                    "locations_changed": comparison.get('locations_changed', False)
                }
                
                symptom_summary[f"{api_name}_baseline_outcome"] = baseline_outcome
                symptom_summary[f"{api_name}_with_rag_outcome"] = rag_outcome
                symptom_summary[f"{api_name}_improvement"] = improvement_analysis
            
            # ä½¿ç”¨ç—‡çŠ¶æ–‡æœ¬çš„å‰50ä¸ªå­—ç¬¦ä½œä¸ºé”®å
            symptom_key = symptom_text[:50] + "..." if len(symptom_text) > 50 else symptom_text
            evaluation_summary[symptom_key] = symptom_summary
        
        return {
            "report_id": self.report_id,
            "timestamp": datetime.now().isoformat(),
            "total_symptoms": len(evaluation_summary),
            "symptoms": evaluation_summary
        }

    def _generate_score_report(self, simplified_results: Dict[str, Any], result_folder: Path, timestamp: str) -> Path:
        """ç”ŸæˆRAGæ•ˆæžœåˆ†æ•°æŠ¥å‘Š (TXTæ ¼å¼)"""
        report_path = result_folder / f"report_{self.report_id}_rag_score_report.txt"
        
        # æ”¶é›†æ‰€æœ‰APIåç§°
        api_names = set()
        for symptom_data in simplified_results['symptoms'].values():
            for key in symptom_data.keys():
                if key.endswith('_improvement'):
                    api_name = key.replace('_improvement', '')
                    api_names.add(api_name)
        
        api_names = sorted(list(api_names))
        
        # å‡†å¤‡ç»Ÿè®¡æ•°æ®
        api_stats = {}
        for api_name in api_names:
            api_stats[api_name] = {
                'precision_improvements': [],
                'recall_improvements': [],
                'f1_improvements': [],
                'overall_improvements': [],
                'positive_effects': 0,
                'negative_effects': 0,
                'no_effects': 0,
                'organ_improvements': 0
            }
        
        # æ”¶é›†æ¯ä¸ªç—‡çŠ¶çš„æ•°æ®
        symptom_details = []
        for symptom_name, symptom_data in simplified_results['symptoms'].items():
            symptom_info = {
                'name': symptom_name,
                'apis': {}
            }
            
            for api_name in api_names:
                improvement_key = f"{api_name}_improvement"
                if improvement_key in symptom_data:
                    improvement = symptom_data[improvement_key]
                    metrics = improvement.get('metrics_improvement', {})
                    
                    # æ”¶é›†ç»Ÿè®¡æ•°æ®
                    precision_imp = metrics.get('precision_improvement', 0)
                    recall_imp = metrics.get('recall_improvement', 0)
                    f1_imp = metrics.get('f1_improvement', 0)
                    overall_imp = metrics.get('overall_improvement', 0)
                    
                    api_stats[api_name]['precision_improvements'].append(precision_imp)
                    api_stats[api_name]['recall_improvements'].append(recall_imp)
                    api_stats[api_name]['f1_improvements'].append(f1_imp)
                    api_stats[api_name]['overall_improvements'].append(overall_imp)
                    
                    # åˆ†ç±»æ•ˆæžœ
                    if overall_imp > 0:
                        api_stats[api_name]['positive_effects'] += 1
                    elif overall_imp < 0:
                        api_stats[api_name]['negative_effects'] += 1
                    else:
                        api_stats[api_name]['no_effects'] += 1
                    
                    # å™¨å®˜æ”¹å–„
                    if improvement.get('organ_improved', False):
                        api_stats[api_name]['organ_improvements'] += 1
                    
                    # ä¿å­˜ç—‡çŠ¶è¯¦æƒ…
                    symptom_info['apis'][api_name] = {
                        'precision_improvement': precision_imp,
                        'recall_improvement': recall_imp,
                        'f1_improvement': f1_imp,
                        'overall_improvement': overall_imp,
                        'assessment': improvement.get('assessment', ''),
                        'organ_improved': improvement.get('organ_improved', False),
                        'locations_changed': improvement.get('locations_changed', False)
                    }
            
            symptom_details.append(symptom_info)
        
        # è®¡ç®—å¹³å‡å€¼
        for api_name in api_names:
            stats = api_stats[api_name]
            if stats['precision_improvements']:
                stats['avg_precision'] = sum(stats['precision_improvements']) / len(stats['precision_improvements'])
                stats['avg_recall'] = sum(stats['recall_improvements']) / len(stats['recall_improvements'])
                stats['avg_f1'] = sum(stats['f1_improvements']) / len(stats['f1_improvements'])
                stats['avg_overall'] = sum(stats['overall_improvements']) / len(stats['overall_improvements'])
            else:
                stats['avg_precision'] = 0.0
                stats['avg_recall'] = 0.0
                stats['avg_f1'] = 0.0
                stats['avg_overall'] = 0.0
        
        # ç”ŸæˆæŠ¥å‘Š
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write(f"RAG æ•ˆæžœåˆ†æžæŠ¥å‘Š - Report {self.report_id}\n")
            f.write("=" * 80 + "\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {timestamp}\n")
            f.write(f"æ€»ç—‡çŠ¶æ•°: {len(symptom_details)}\n")
            f.write(f"è¯„æµ‹APIs: {', '.join(api_names)}\n")
            f.write("\n")
            
            # 1. æ€»ä½“æ•ˆæžœæ¦‚è§ˆ
            f.write("â–ˆ æ€»ä½“æ•ˆæžœæ¦‚è§ˆ\n")
            f.write("-" * 60 + "\n")
            for api_name in api_names:
                stats = api_stats[api_name]
                total_symptoms = len(stats['overall_improvements'])
                f.write(f"\nã€{api_name.upper()}ã€‘\n")
                f.write(f"  âœ… æ”¹å–„ç—‡çŠ¶: {stats['positive_effects']}/{total_symptoms} ({stats['positive_effects']/total_symptoms*100:.1f}%)\n")
                f.write(f"  âŒ è´Ÿé¢å½±å“: {stats['negative_effects']}/{total_symptoms} ({stats['negative_effects']/total_symptoms*100:.1f}%)\n")
                f.write(f"  âšª æ— æ˜Žæ˜¾å˜åŒ–: {stats['no_effects']}/{total_symptoms} ({stats['no_effects']/total_symptoms*100:.1f}%)\n")
                f.write(f"  ðŸŽ¯ å™¨å®˜è¯†åˆ«æ”¹å–„: {stats['organ_improvements']}/{total_symptoms} ({stats['organ_improvements']/total_symptoms*100:.1f}%)\n")
            f.write("\n")
            
            # 2. å¹³å‡æŒ‡æ ‡æ”¹å–„
            f.write("â–ˆ å¹³å‡æŒ‡æ ‡æ”¹å–„\n")
            f.write("-" * 60 + "\n")
            f.write(f"{'API':<12} {'ç²¾ç¡®çŽ‡':<10} {'å¬å›žçŽ‡':<10} {'F1åˆ†æ•°':<10} {'ç»¼åˆå¾—åˆ†':<10}\n")
            f.write("-" * 60 + "\n")
            for api_name in api_names:
                stats = api_stats[api_name]
                f.write(f"{api_name:<12} ")
                f.write(f"{stats['avg_precision']:+6.1f}%   ")
                f.write(f"{stats['avg_recall']:+6.1f}%   ")
                f.write(f"{stats['avg_f1']:+6.1f}%   ")
                f.write(f"{stats['avg_overall']:+6.1f}åˆ†\n")
            f.write("\n")
            
            # 3. å„ç—‡çŠ¶è¯¦ç»†åˆ†æž
            f.write("â–ˆ å„ç—‡çŠ¶è¯¦ç»†åˆ†æž\n")
            f.write("-" * 80 + "\n")
            for i, symptom_info in enumerate(symptom_details, 1):
                f.write(f"\n{i}. ã€{symptom_info['name']}ã€‘\n")
                f.write("-" * 40 + "\n")
                
                for api_name in api_names:
                    if api_name in symptom_info['apis']:
                        api_data = symptom_info['apis'][api_name]
                        f.write(f"\n  [{api_name.upper()}]\n")
                        f.write(f"    ç²¾ç¡®çŽ‡æ”¹å–„: {api_data['precision_improvement']:+6.1f}%\n")
                        f.write(f"    å¬å›žçŽ‡æ”¹å–„: {api_data['recall_improvement']:+6.1f}%\n")
                        f.write(f"    F1åˆ†æ•°æ”¹å–„: {api_data['f1_improvement']:+6.1f}%\n")
                        f.write(f"    ç»¼åˆå¾—åˆ†æ”¹å–„: {api_data['overall_improvement']:+6.1f}åˆ†\n")
                        f.write(f"    å™¨å®˜è¯†åˆ«æ”¹å–„: {'æ˜¯' if api_data['organ_improved'] else 'å¦'}\n")
                        f.write(f"    ä½ç½®ä¿¡æ¯å˜åŒ–: {'æ˜¯' if api_data['locations_changed'] else 'å¦'}\n")
                        f.write(f"    æ€»ä½“è¯„ä¼°: {api_data['assessment']}\n")
                f.write("\n")
            
            # 4. ç»“è®ºä¸Žå»ºè®®
            f.write("â–ˆ ç»“è®ºä¸Žå»ºè®®\n")
            f.write("-" * 60 + "\n")
            
            # æ‰¾å‡ºè¡¨çŽ°æœ€å¥½å’Œæœ€å·®çš„API
            best_api = max(api_names, key=lambda x: api_stats[x]['avg_overall'])
            worst_api = min(api_names, key=lambda x: api_stats[x]['avg_overall'])
            
            f.write(f"\nã€æœ€ä½³è¡¨çŽ°APIã€‘: {best_api.upper()}\n")
            f.write(f"  å¹³å‡ç»¼åˆå¾—åˆ†æ”¹å–„: {api_stats[best_api]['avg_overall']:+.1f}åˆ†\n")
            f.write(f"  æ”¹å–„ç—‡çŠ¶æ¯”ä¾‹: {api_stats[best_api]['positive_effects']/len(api_stats[best_api]['overall_improvements'])*100:.1f}%\n")
            
            f.write(f"\nã€éœ€è¦æ”¹è¿›APIã€‘: {worst_api.upper()}\n")
            f.write(f"  å¹³å‡ç»¼åˆå¾—åˆ†æ”¹å–„: {api_stats[worst_api]['avg_overall']:+.1f}åˆ†\n")
            f.write(f"  è´Ÿé¢å½±å“ç—‡çŠ¶æ¯”ä¾‹: {api_stats[worst_api]['negative_effects']/len(api_stats[worst_api]['overall_improvements'])*100:.1f}%\n")
            
            # æ€»ä½“RAGæ•ˆæžœè¯„ä¼°
            total_positive = sum(stats['positive_effects'] for stats in api_stats.values())
            total_negative = sum(stats['negative_effects'] for stats in api_stats.values())
            total_evaluations = sum(len(stats['overall_improvements']) for stats in api_stats.values())
            
            f.write(f"\nã€æ€»ä½“RAGæ•ˆæžœã€‘:\n")
            f.write(f"  ç§¯æžå½±å“: {total_positive}/{total_evaluations} ({total_positive/total_evaluations*100:.1f}%)\n")
            f.write(f"  è´Ÿé¢å½±å“: {total_negative}/{total_evaluations} ({total_negative/total_evaluations*100:.1f}%)\n")
            
            if total_positive > total_negative:
                f.write(f"  ðŸŽ¯ ç»“è®º: RAGå¢žå¼ºæ€»ä½“ä¸Š**æœ‰æ•ˆ**ï¼Œå»ºè®®ç»§ç»­ä½¿ç”¨å’Œä¼˜åŒ–\n")
            elif total_positive < total_negative:
                f.write(f"  âš ï¸  ç»“è®º: RAGå¢žå¼ºå­˜åœ¨é—®é¢˜ï¼Œå»ºè®®æ£€æŸ¥æ£€ç´¢è´¨é‡å’Œå¢žå¼ºç­–ç•¥\n")
            else:
                f.write(f"  âšª ç»“è®º: RAGå¢žå¼ºæ•ˆæžœä¸æ˜Žæ˜¾ï¼Œå»ºè®®ä¼˜åŒ–æ£€ç´¢æ¨¡åž‹å’Œå¢žå¼ºæ–¹æ³•\n")
            
            f.write("\n" + "=" * 80 + "\n")
        
        return report_path


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ä½¿ç”¨å·²æœ‰çš„RAGæ£€ç´¢ç»“æžœé‡æ–°è¿è¡ŒLLMè¯„ä¼°ã€‚")
    parser.add_argument("report_id", type=int, help="éœ€è¦å¤„ç†çš„æŠ¥å‘ŠID (ä¾‹å¦‚: 4000)")
    parser.add_argument("--config", default="config/config.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    args = parser.parse_args()

    workflow = RerunWorkflow(args.report_id, args.config)
    workflow.run()
